# -*- coding: utf-8 -*-
"""Hackhathon2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U4n79n78kItsL9xrybqBYIy2ye_7xX07
"""

!pip install streamlit
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, classification_report, confusion_matrix
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("Digital detox 3.csv")
df.head()

df.shape

df.isnull().sum()

df.drop("Gender", axis=1, inplace=True)
display(df.describe())

plt.figure(figsize=(10,6))
sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=".2f", cmap="coolwarm", center=0)
plt.title("Correlation Heatmap")
plt.show()

#features selection
features_reg = [
    "Detox Duration",
    "Baseline Mood",
    "Baseline Stress",
    "Screen Time",
    "Baseline Sleep",
    "Baseline Focus",
    "Sleep Hours"
]
X_reg = df[features_reg]
y_reg = df["Mood Change"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)

# Initialize and train the Linear Regression model
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = linear_model.predict(X_test)

# Evaluate the model
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"R2 score: {r2:.2f}")
print(f"RMSE: {rmse:.2f}")

plt.figure(figsize=(6,5))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual Mood Change")
plt.ylabel("Predicted Mood Change")
plt.title("Actual vs Predicted (Mood Improvement)")
plt.show()

# logistic regression
features_log = [
    "Detox Duration",
    "Baseline Mood",
    "Baseline Stress",
    "Screen Time",
    "Baseline Sleep",
    "Baseline Focus",
    "Sleep Hours"
]
X_log = df[features_log]
y_log = df["Difficulty Level"]

# Encode the target variable
label_encoder = LabelEncoder()
y_log_encoded = label_encoder.fit_transform(y_log)

# Split the data into training and testing sets
X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_log, y_log_encoded, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_log_scaled = scaler.fit_transform(X_train_log)
X_test_log_scaled = scaler.transform(X_test_log)


# Initialize and train the Logistic Regression model
logistic_model = LogisticRegression(max_iter=200)
logistic_model.fit(X_train_log_scaled, y_train_log)

# Make predictions on the test set
y_pred_log = logistic_model.predict(X_test_log_scaled)

# Evaluate the model
accuracy = accuracy_score(y_test_log, y_pred_log)
classification_rep = classification_report(y_test_log, y_pred_log, target_names=label_encoder.classes_)
conf_matrix = confusion_matrix(y_test_log, y_pred_log)

print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:\n", classification_rep)
print("Confusion Matrix:\n", conf_matrix)

joblib.dump(linear_model, "linear_mood_change_model.joblib")
joblib.dump(scaler, "scaler_clf.joblib")
joblib.dump(scaler, "scaler_reg.joblib")
joblib.dump(logistic_model, "logistic_difficulty_model.joblib")
joblib.dump(label_encoder, "label_encoder_difficulty.joblib")